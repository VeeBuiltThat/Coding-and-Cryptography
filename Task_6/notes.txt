1. Huffman Tree (Used by Hybrid Compression)
The program includes a small Huffman coding system:
Each pixel value or (value, count) tuple is treated as a “symbol.”
A frequency map is built.
A Huffman tree is constructed using a priority queue.
Symbols that appear more often get shorter bit codes.
Used for efficient lossless compression of RLE output.


2. Hybrid Compression (Lossy + Lossless)
Steps inside compress_hybrid():
Convert the image to grayscale.
Apply quantization → divide each pixel by quant_factor (lossy).
Flatten the image and perform Run-Length Encoding (RLE).
Build a Huffman dictionary based on how often each RLE pair appears.
Convert the RLE sequence to a bitstream using the Huffman codes.

Save:
Shape of the image
Quantization factor
Huffman codes
Compressed bitstream
Decompression (decompress_hybrid()):
Load header and Huffman codes.
Decode the bitstream back into RLE pairs.
Reconstruct the quantized pixel values.
Multiply by the quantization factor (reverse quantization).
Reshape and save the final image.
In simple words:
 Hybrid = quantization (lossy) + RLE (lossless) + Huffman (lossless).

3. RLE v2 (Improved Binary Run-Length Encoding)
compress_rle_v2():
Stores image dimensions in the first 4 bytes.
Then stores (value, count) pairs, each using 1 byte.
If run length > 255, it splits it across multiple pairs.
Very compact for simple images with large uniform areas.
decompress_rle_v2():
Reads height + width.
Reads all (value, count) pairs.
Reconstructs the flattened pixel array.
Reshapes and saves the image.
In simple words:
 RLE v2 is a lightweight binary compressor that works best on images with big regions of the same color.

4. RLE Scanline Compression (Horizontal or Vertical)
compress_rle_scan():
Choose scan direction:
Horizontal (each row)
Vertical (each column)
For each scanline:
Perform RLE.
Store how many RLE pairs there are.
Save a header containing:
Height
Width
Mode (1 = horizontal, 2 = vertical)
decompress_rle_scan():
Reads the header.
Rebuilds each row or column from RLE pairs.
Reconstructs the full image.
Main purpose:
 Compare whether horizontal or vertical scanning compresses better.
 Works well on patterns such as stripes or gradients.

5. JPEG Quality Analysis
jpeg_quality_analysis():
Saves the image multiple times using different JPEG quality settings.

Measures:
File size
Distortion (MSE – Mean Squared Error)
Can optionally show plots:
Quality vs File Size
Quality vs MSE
Rate–Distortion curve
Goal: Understand how JPEG quality affects image size and visual quality.

6. Helper Functions (dont mind this, saving this here for future project)
create_test_simple()
Creates a simple synthetic image for compression testing.
compare_rle_scan()
Runs compression both horizontally and vertically and prints sizes.
print_help() and main()
Provide command-line interface support:
hybrid compress/decompress
rle_v2 compress/decompress
rle_scan compress/decompress/compare
jpeg_analysis
In the Simplest Terms Possible
This program includes:
Method
Type
Purpose
Hybrid
Lossy + Lossless
Strong compression using quantization + RLE + Huffman
RLE v2
Lossless
Simple and fast binary compression
RLE Scan
Lossless
Tests horizontal vs vertical compression efficiency
JPEG Analysis
Lossy
Shows effect of JPEG quality settings

-- dont mind this part --
import os  
import sys 
import heapq 
import pickle 
from collections import defaultdict  
from PIL import Image 
import numpy as np

try:
    import matplotlib.pyplot as plt  
except Exception:
    plt = None

try:
    from skimage.metrics import mean_squared_error  
except Exception:
    mean_squared_error = None

# mini huffman code system
class HuffmanNode:  # 1) Huffman node for a symbol and its frequency
    def __init__(self, value, freq):
        self.value = value  # symbol (pixel or (value,count) tuple)
        self.freq = freq
        self.left = None 
        self.right = None 
    def __lt__(self, other):
        return self.freq < other.freq  # priority by freq for heapq

def build_huffman_tree_from_freq(freq_map):  # build tree from frequency map using a priority queue
    pq = []
    for val, f in freq_map.items():
        heapq.heappush(pq, HuffmanNode(val, f))
    if not pq:
        return None
    while len(pq) > 1:
        a = heapq.heappop(pq)
        b = heapq.heappop(pq) 
        parent = HuffmanNode(None, a.freq + b.freq)  # internal node
        parent.left = a
        parent.right = b
        heapq.heappush(pq, parent)  # push merged node
    return pq[0]
# tree is made to use a priority queue

def generate_codes_from_tree(root):  # traverse tree to build binary codes (strings) for each symbol
    codes = {}
    if root is None:
        return codes
    def dfs(node, prefix):
        if node.value is not None:
            codes[node.value] = prefix or "0"  # assign code, use "0" for single-node tree
            return
        dfs(node.left, prefix + "0")
        dfs(node.right, prefix + "1")
    dfs(root, "")
    return codes

def compress_hybrid(input_file, output_file, quant_factor=10):  # 2) Hybrid: grayscale -> quantize -> RLE -> Huffman (lossy+lossless)
# Compresses, lossy + lossless
    print(f"Hybrid compress: {input_file} -> {output_file} (quant={quant_factor})")
    image = Image.open(input_file).convert('L')  # convert to grayscale (lossy step starts after quant)
    arr = np.array(image)
    shape = arr.shape  # save shape for decompression

    q = (arr // quant_factor).astype(np.uint8)  # quantization (lossy): divide pixels by quant_factor

    flat = q.flatten()  # flatten for RLE
    rle = []
    if flat.size == 0:
        print("Empty image.")
        return
    cur_val = int(flat[0])
    cnt = 1
    for pix in flat[1:]:
        pix = int(pix)
        if pix == cur_val and cnt < 65535: 
            cnt += 1  # extend run
        else:
            rle.append((cur_val, cnt))  # store RLE pair (value, count)
            cur_val = pix
            cnt = 1
    rle.append((cur_val, cnt))

    freq = defaultdict(int)  # frequency map over RLE symbols for Huffman
    for sym in rle:
        freq[sym] += 1

    root = build_huffman_tree_from_freq(freq)  # build Huffman tree from frequencies
    codes = generate_codes_from_tree(root)  # generate bit codes for each RLE symbol

    bitstr = "".join(codes[sym] for sym in rle)  # encode RLE sequence into a bitstring using Huffman codes

    with open(output_file, 'wb') as f:
        header = {'shape': shape, 'quant_factor': quant_factor, 'codes': codes}  # header contains shape, quant, codes
        pickle.dump(header, f)

        padding = (8 - (len(bitstr) % 8)) % 8
        f.write(bytes([padding]))  # write padding length byte
        if padding:
            bitstr += '0' * padding  # pad bitstring to full byte

        ba = bytearray()
        for i in range(0, len(bitstr), 8):
            ba.append(int(bitstr[i:i+8], 2))  # pack bits into bytes
        f.write(ba)

    print("Hybrid compression written. Original size:", os.path.getsize(input_file),
          "Compressed size:", os.path.getsize(output_file))

def decompress_hybrid(input_file, output_file):  # decode header + Huffman bitstream -> RLE -> restore quantized values -> dequantize

    print(f"Hybrid decompress: {input_file} -> {output_file}")
    with open(input_file, 'rb') as f:
        header = pickle.load(f)  # load header
        shape = tuple(header['shape'])  # expected output shape
        quant_factor = header['quant_factor']  # quant factor used during compress
        codes = header['codes']  # Huffman codes map

        inverted = {v:k for k,v in codes.items()}  # invert codes for decoding
        padding = int.from_bytes(f.read(1), 'big')  # read padding byte
        data = f.read()
        bitstr = ''.join(f'{byte:08b}' for byte in data)  # convert bytes to bitstring
        if padding:
            bitstr = bitstr[:-padding]  # remove padding bits

        cur = ""
        rle = []
        for b in bitstr:
            cur += b
            if cur in inverted:
                rle.append(inverted[cur])  # append decoded RLE symbol
                cur = ""


    flat = []
    for val, cnt in rle:
        flat.extend([int(val)] * int(cnt))  # expand RLE pairs into flattened pixel list

    if len(flat) != shape[0] * shape[1]:
        print(f"Warning: decompressed pixel count {len(flat)} != expected {shape[0]*shape[1]}.")  # sanity check

        if len(flat) > shape[0]*shape[1]:
            flat = flat[:shape[0]*shape[1]]  # trim if too long
        else:
            flat.extend([0] * (shape[0]*shape[1] - len(flat)))  # pad with zeros if too short

    arr = (np.array(flat, dtype=np.uint8).reshape(shape) * quant_factor).astype(np.uint8)  # dequantize by multiplying
    Image.fromarray(arr).save(output_file)
    print("Hybrid decompressed image saved.")

def compress_rle_v2(input_file, output_file):  # 3) RLE v2: binary RLE with dims first then (value,count) pairs (1 byte each)

    print(f"RLEv2 compress: {input_file} -> {output_file}")
    image = Image.open(input_file).convert('L')  # grayscale
    arr = np.array(image)
    h, w = arr.shape
    flat = arr.flatten()

    with open(output_file, 'wb') as f:
        f.write(h.to_bytes(2, 'big'))  # write height (2 bytes)
        f.write(w.to_bytes(2, 'big'))  # write width  (2 bytes)
        if flat.size == 0:
            return
        cur = int(flat[0])
        cnt = 1
        for pix in flat[1:]:
            pix = int(pix)
            if pix == cur:
                cnt += 1
                if cnt == 256:
                    f.write(bytes([cur, 255]))  # flush run chunk when >255
                    cnt = 1
            else:

                while cnt > 255:
                    f.write(bytes([cur, 255]))  # split long runs into 255-chunks
                    cnt -= 255
                f.write(bytes([cur, cnt]))  # write (value,count)
                cur = pix
                cnt = 1

        while cnt > 255:
            f.write(bytes([cur, 255]))  # final flush for long run
            cnt -= 255
        f.write(bytes([cur, cnt]))  # final pair
    print("RLE v2 written. sizes:", os.path.getsize(input_file), "->", os.path.getsize(output_file))

def decompress_rle_v2(input_file, output_file):  # read dims then pairs, expand to pixels and reshape
    print(f"RLEv2 decompress: {input_file} -> {output_file}")
    with open(input_file, 'rb') as f:
        header = f.read(4)
        if len(header) < 4:
            print("Invalid file.")
            return
        h = int.from_bytes(header[0:2], 'big')  # height
        w = int.from_bytes(header[2:4], 'big')  # width
        flat = []
        while True:
            pair = f.read(2)
            if not pair or len(pair) < 2:
                break
            value = pair[0]
            cnt = pair[1]
            flat.extend([value] * cnt)  # expand each (value,count)
    if len(flat) != h*w:
        print(f"Warning: decompressed length {len(flat)} != expected {h*w}. Adjusting.")  # sanity
        if len(flat) > h*w:
            flat = flat[:h*w]
        else:
            flat.extend([0]*(h*w - len(flat)))
    arr = np.array(flat, dtype=np.uint8).reshape((h,w))
    Image.fromarray(arr).save(output_file)
    print("RLEv2 decompressed image saved.")


def create_test_simple(path="test_simple.png", w=200, h=200):  # helper test image generator (simple blocks/stripe)
    arr = np.zeros((h,w), dtype=np.uint8)
    arr[0:100, :] = 50  # block of mid-gray
    arr[:, 150:160] = 255  # vertical white stripe
    Image.fromarray(arr).save(path)
    print("Test image saved to", path)

def compress_rle_scan(input_file, output_file, mode='horizontal'):  # 4) RLE scan: per-scanline RLE, supports horizontal or vertical scan

    print(f"RLE scan compress: {input_file} -> {output_file} mode={mode}")
    image = Image.open(input_file).convert('L')  # grayscale
    arr = np.array(image)
    h,w = arr.shape

    if mode == 'horizontal':
        lines = [arr[row,:] for row in range(h)]  # each row is a scanline
        mode_byte = 1
    elif mode == 'vertical':
        lines = [arr[:,col] for col in range(w)]  # each column is a scanline
        mode_byte = 2
    else:
        raise ValueError("mode must be 'horizontal' or 'vertical'")

    with open(output_file, 'wb') as f:
        f.write(h.to_bytes(2,'big'))  # write height
        f.write(w.to_bytes(2,'big'))  # write width
        f.write(bytes([mode_byte]))  # write mode byte (1=horiz,2=vert)
        for line in lines:

            pairs = []
            cur = int(line[0])
            cnt = 1
            for pix in line[1:]:
                pix = int(pix)
                if pix == cur:
                    cnt += 1
                    if cnt == 256:
                        pairs.append((cur,255)); cnt = 1  # split run >255
                else:
                    while cnt > 255:
                        pairs.append((cur,255)); cnt -= 255  # split long runs
                    pairs.append((cur,cnt))  # append (value,count)
                    cur = pix; cnt = 1
            while cnt > 255:
                pairs.append((cur,255)); cnt -= 255
            pairs.append((cur,cnt))

            f.write(len(pairs).to_bytes(2,'big'))  # number of pairs for this scanline

            for val,c in pairs:
                f.write(bytes([val, c]))  # write each pair as two bytes

    print("RLE-scan file written:", os.path.getsize(output_file), "bytes")

def decompress_rle_scan(input_file, output_file):  # read header, rebuild each scanline and assemble image
    with open(input_file,'rb') as f:
        header = f.read(5)
        if len(header) < 5:
            print("Invalid file")
            return
        h = int.from_bytes(header[0:2],'big')  # height
        w = int.from_bytes(header[2:4],'big')  # width
        mode_byte = header[4]  # scan mode
        if mode_byte == 1:
            horizontal = True
            lines_count = h
        else:
            horizontal = False
            lines_count = w

        if horizontal:
            result = np.zeros((h,w), dtype=np.uint8)
        else:
            result = np.zeros((h,w), dtype=np.uint8)

        for line_idx in range(lines_count):
            n_pairs = int.from_bytes(f.read(2), 'big')  # number of RLE pairs for this line
            flat_line = []
            for _ in range(n_pairs):
                pair = f.read(2)
                val = pair[0]; cnt = pair[1]
                flat_line.extend([val]*cnt)  # expand pairs into flat line

            if horizontal:
                row = np.array(flat_line[:w], dtype=np.uint8)
                if row.size < w:
                    row = np.concatenate([row, np.zeros(w-row.size,dtype=np.uint8)])  # pad if short
                result[line_idx,:] = row
            else:
                col = np.array(flat_line[:h], dtype=np.uint8)
                if col.size < h:
                    col = np.concatenate([col, np.zeros(h-col.size,dtype=np.uint8)])
                result[:,line_idx] = col

    Image.fromarray(result).save(output_file)
    print("RLE-scan decompressed saved to", output_file)

def compare_rle_scan(test_image="test_simple.png", natural_image="sample.png"):  # helper: compare horiz vs vert compression
    if not os.path.exists(test_image):
        create_test_simple(test_image)

    hfile = "test_simple.hrle"
    vfile = "test_simple.vrle"
    compress_rle_scan(test_image, hfile, 'horizontal')  # compress horizontally
    compress_rle_scan(test_image, vfile, 'vertical')  # compress vertically
    size_h = os.path.getsize(hfile)
    size_v = os.path.getsize(vfile)
    print("Sizes for", test_image, "-> horizontal:", size_h, "vertical:", size_v)
    
    decompress_rle_scan(hfile, "test_simple_hrle_decomp.png")
    decompress_rle_scan(vfile, "test_simple_vrle_decomp.png")

    if os.path.exists(natural_image):
        hfile2 = "sample.hrle"
        vfile2 = "sample.vrle"
        compress_rle_scan(natural_image, hfile2, 'horizontal')
        compress_rle_scan(natural_image, vfile2, 'vertical')
        print("Sizes for natural image -> horizontal:", os.path.getsize(hfile2),
              "vertical:", os.path.getsize(vfile2))
    else:
        print("Natural image not found; skipped natural photo test.")


def jpeg_quality_analysis(input_file, qualities=None, plot=False):  # 5) JPEG quality analysis: size vs MSE across qualities
    if mean_squared_error is None:
        print("skimage.metrics.mean_squared_error not available. Install scikit-image.")
        return
    if qualities is None:
        qualities = [5,10,15,25,50,75,85,95]  # default quality list
    orig_img = Image.open(input_file).convert('RGB')  # use RGB for JPEG analysis
    orig_arr = np.array(orig_img)
    file_sizes = []
    errors = []
    temp_files = []
    for q in qualities:
        out = f"temp_q{q}.jpg"
        orig_img.convert('RGB').save(out, "JPEG", quality=q)  # save JPEG at quality q
        temp_files.append(out)
        size = os.path.getsize(out)
        file_sizes.append(size)
        recon = np.array(Image.open(out).convert('RGB'))
        mse = mean_squared_error(orig_arr.astype(np.float32), recon.astype(np.float32))  # compute MSE
        errors.append(mse)
        print(f"Quality {q}: size={size} bytes, MSE={mse:.2f}")

    print("\nQuality | Size (bytes) | MSE")
    for q,s,e in zip(qualities, file_sizes, errors):
        print(f"{q:3}     {s:10}       {e:.2f}")

    if plot and plt is not None:
        plt.figure(figsize=(12,4))
        plt.subplot(1,3,1)
        plt.plot(qualities, file_sizes, marker='o')  # plot size vs quality
        plt.title("File Size vs Quality")
        plt.xlabel("Quality"); plt.ylabel("Size (bytes)")
        plt.subplot(1,3,2)
        plt.plot(qualities, errors, marker='o')  # plot MSE vs quality
        plt.title("MSE vs Quality")
        plt.xlabel("Quality"); plt.ylabel("MSE")
        plt.subplot(1,3,3)
        plt.plot(file_sizes, errors, marker='o')  # rate-distortion curve
        plt.title("Rate-Distortion (MSE vs Size)")
        plt.xlabel("Size (bytes)"); plt.ylabel("MSE")
        plt.tight_layout()
        plt.show()


def print_help():  # helper: print module docstring/help
    print(__doc__)

def compress_all_png_in_folder(folder_path=".", compression_method='hybrid', quant_factor=10):  # batch helper for PNGs
   
    print(f"Searching for .png files in {folder_path}...")
    
    png_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.png')]  # list pngs
    
    if not png_files:
        print("No .png files found.")
        return
    
    print(f"Found {len(png_files)} .png file(s): {png_files}\n")
    
    for png_file in png_files:
        input_path = os.path.join(folder_path, png_file)
        
        if compression_method == 'hybrid':
            output_path = os.path.join(folder_path, f"{png_file}.hybrid")
            compress_hybrid(input_path, output_path, quant_factor=quant_factor)  # run hybrid
        elif compression_method == 'rle_v2':
            output_path = os.path.join(folder_path, f"{png_file}.rle_v2")
            compress_rle_v2(input_path, output_path)  # run rle_v2
        elif compression_method == 'rle_scan':
            output_path = os.path.join(folder_path, f"{png_file}.rle_scan")
            compress_rle_scan(input_path, output_path, mode='horizontal')  # run rle_scan horizontal
        
        print()

def main(argv):  # CLI dispatcher: hybrid, rle_v2, rle_scan, compress_all, jpeg_analysis
    if len(argv) < 2:
        print_help(); return
    cmd = argv[1].lower()
    if cmd == 'hybrid':
        if len(argv) < 4:
            print("Usage: hybrid [compress|decompress] in out"); return
        action = argv[2]; infile = argv[3]; outfile = argv[4]
        if action == 'compress':
            compress_hybrid(infile, outfile, quant_factor=10)
        else:
            decompress_hybrid(infile, outfile)
    elif cmd == 'rle_v2':
        if len(argv) < 4:
            print("Usage: rle_v2 [compress|decompress] in out"); return
        action = argv[2]; infile = argv[3]; outfile = argv[4]
        if action == 'compress':
            compress_rle_v2(infile, output_file=outfile)
        else:
            decompress_rle_v2(infile, outfile)
    elif cmd == 'rle_scan':
        if len(argv) < 3:
            print("Usage: rle_scan [compress|decompress|compare] ..."); return
        action = argv[2]
        if action == 'compare':
            test_img = argv[3] if len(argv)>3 else "test_simple.png"
            compare_rle_scan(test_img)
        elif action == 'compress':
            mode = argv[4] if len(argv)>4 else 'horizontal'
            compress_rle_scan(argv[3], argv[4], mode)
        elif action == 'decompress':
            decompress_rle_scan(argv[3], argv[4])
    elif cmd == 'compress_all':
        folder = argv[2] if len(argv)>2 else "."
        method = argv[3] if len(argv)>3 else 'hybrid'
        quant = int(argv[4]) if len(argv)>4 else 10
        compress_all_png_in_folder(folder, method, quant)
    elif cmd == 'jpeg_analysis':
        if len(argv) < 3:
            print("Usage: jpeg_analysis input.png [plot]"); return
        plot = (len(argv)>3 and argv[3].lower()=='plot')
        jpeg_quality_analysis(argv[2], plot=plot)
    else:
        print_help()

if __name__ == "__main__":
    main(sys.argv)
